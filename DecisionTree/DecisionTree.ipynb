{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf545bb",
   "metadata": {},
   "source": [
    "# Decision Tree Exercise\n",
    "A) Find some data here [1] on people. The goal is to decide if someone buys a computer or not. Derive the best decision tree by calculating a little by hand (Shannon). At least the first split.\n",
    "\n",
    "B) Compare your tree against the tree derived from SciKit Learn as given in the Python example before! Why are they different? Print the tree with Graphviz (can be easily done with WebGraphViz [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15289cc",
   "metadata": {},
   "source": [
    "## A. Derive decision tree by hand\n",
    "### The data\n",
    "![data](data.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f17958",
   "metadata": {},
   "source": [
    "### Step 1: Calculate entropy on the target\n",
    "![step1](step1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0a725",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Information Gain on each branch\n",
    "#### Entropy using the frequency table of two attributes and Information Gain on \"Age\"\n",
    "![age](age.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f607449",
   "metadata": {},
   "source": [
    "#### Information Gain on all branches \"Age\", \"Income\", \"Student\" and \"CreditRating\"\n",
    "![all](all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f96e3",
   "metadata": {},
   "source": [
    "### Step 3: Choose attribute with the largest information gain as the decision node, divide the dataset by its branches and repeat the same process on every branch.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84ce1",
   "metadata": {},
   "source": [
    "#### The branch with the largest information gain is \"Age\"\n",
    "![age1](age1.png)\n",
    "\n",
    "#### Sort the data by \"Age\"\n",
    "![sort](sort.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e37897",
   "metadata": {},
   "source": [
    "### Step 4a: A branch with entropy of 0 is a leaf node.\t\n",
    "![4a](4a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e20a5",
   "metadata": {},
   "source": [
    "### Step 4b: A branch with entropy more than 0 needs further splitting.\t\n",
    "![step4b](4b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48668bae",
   "metadata": {},
   "source": [
    "### Step 5: The algorithm is run recursively on the non-leaf branches, until all data is classified.\t\n",
    "![tree](tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80045048",
   "metadata": {},
   "source": [
    "## B. Decision Tree with SciKit Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1905eff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Student</th>\n",
       "      <th>Credit_rating</th>\n",
       "      <th>Buys_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Income  Student  Credit_rating  Buys_computer\n",
       "0     0       2        0              0              0\n",
       "1     0       2        0              1              0\n",
       "2     1       2        0              0              1\n",
       "3     2       1        0              0              1\n",
       "4     2       0        1              0              1\n",
       "5     2       0        1              1              0\n",
       "6     1       0        1              1              1\n",
       "7     0       1        0              0              0\n",
       "8     0       0        1              0              1\n",
       "9     2       1        1              0              1\n",
       "10    0       1        1              1              1\n",
       "11    1       1        0              1              1\n",
       "12    1       2        1              0              1\n",
       "13    2       1        0              1              0\n",
       "14    0       1        0              1              0\n",
       "15    0       0        0              0              0\n",
       "16    0       0        0              1              0\n",
       "17    1       0        1              0              1\n",
       "18    2       1        1              1              1\n",
       "19    1       2        0              1              1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# As SciKit Learn's DecisionTreeClassifier does not support categorical data,\n",
    "# the Age values are transformed to '<=30'=0  '31-40'=1  '>40'=2\n",
    "# the Income values are transformed to 'Low'=0  'Medium'=1  'High'=2\n",
    "# the Student values are transformed to 'No'=0  'Yes'=1\n",
    "# the Credit_rating values are transformed to 'Fair'=0  'Excellent'=1\n",
    "\n",
    "# Creating a dataframe from input file\n",
    "input_file = \"buy_computer_data_numeric.csv\"\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da9b2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tree with criterion=entropy & max_depth=2\n",
    "tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "tree_clf.fit(df[['Age','Income','Student','Credit_rating']], df['Buys_computer'])\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Export the decision tree with criterion=entropy & max_depth = 2\n",
    "export_graphviz(\n",
    "         tree_clf,\n",
    "     out_file=\"computer_tree_entropy_d2.dot\",\n",
    "         feature_names=df.columns[0:4],\n",
    "         class_names=[\"Buys_computer=Yes\", \"Buys_computer=No\"],\n",
    "         rounded=True,\n",
    "         filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6f9ed",
   "metadata": {},
   "source": [
    "#### Decision tree with criterion=entropy & max_depth=2\n",
    "![tree_d2](tree_d2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7272ebc",
   "metadata": {},
   "source": [
    "#### The difference\n",
    "The tree is different from the manually created tree because the values are numeric and thus the splits are different.\n",
    "Moreover, the max_depth = 2 also make the tree simpler than the manually created tree.\n",
    "For a better comparision, we create another tree with max_depth = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "864077ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tree with criterion=entropy & max_depth=5\n",
    "tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "tree_clf.fit(df[['Age','Income','Student','Credit_rating']], df['Buys_computer'])\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Export the decision tree with criterion=entropy & max_depth = 5\n",
    "export_graphviz(\n",
    "         tree_clf,\n",
    "     out_file=\"computer_tree_entropy_d5.dot\",\n",
    "         feature_names=df.columns[0:4],\n",
    "         class_names=[\"Buys_computer=Yes\", \"Buys_computer=No\"],\n",
    "         rounded=True,\n",
    "         filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50fbbe",
   "metadata": {},
   "source": [
    "#### Decision tree with criterion=entropy & max_depth=5\n",
    "![tree_d5](tree_d5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8550a4",
   "metadata": {},
   "source": [
    "With max_depth = 5, the decision tree is now more similar to the tree created in part A of the exercise. However the splits are still different. For features with only 2 values `Yes=1` and `No=0`, the split by `<=0.5` can be translated as `<=0.5`=yes and `>0.5`=no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ec486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
